{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#!pip install netCDF4\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from netCDF4 import Dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression for Scattering\n",
    "So the first concrete example using radar data we will look at is attempting to use random forests for regression. \n",
    "\n",
    "Our goal is to train a random forest regression to predict the DSD based on scattered moments. Ahead of time we have taken data representing drop size distributions that measure the distribution of different raindrop sizes in clouds and done the electromagnetic scattering calculations to turn them into equivalent radar measurements. We've then written these out to a file to make it easier to process here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!wget https://github.com/josephhardinee/weather_radar_ml_course/raw/master/x_scattered_dsds.nc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains several fields. The first three are $D_0$, $N_W$ and $\\mu$. These represent the parameterization of a 3 parameter gamma distribution. If you are not familiar with DSDs, think of $D_0$ as telling you the median size of the drops, $N_W$ as roughly the number of drops, and $\\mu$ as the shape of the distribution. \n",
    "\n",
    "From each of these distributions, we can calculate equivalent radar measurements using T-Matrix scattering theory. This is done using two libraries (PyDSD and PyTMatrix). We have done these calculations for a hypothetical X band radar with a specific configuration. We now want to see if we can use radar measurements to recover the DSD estimates. Note the scattering is a highly nonlinear operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in the data.\n",
    "\n",
    "dset = Dataset('x_scattered_dsds.nc')\n",
    "d0 = dset['D0'][:]\n",
    "nw = dset['Nw'][:]\n",
    "mu = dset['mu'][:]\n",
    "zh = dset['Zh'][:]\n",
    "zdr = dset['Zdr'][:]\n",
    "kdp = dset['Kdp'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get our data in a form more expected by scikit learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array((zh, zdr, kdp)).T\n",
    "y = np.array((d0, nw, mu)).T\n",
    "\n",
    "X_train = X[0:35000]\n",
    "y_train = y[0:35000]\n",
    "\n",
    "X_test = X[35000:]\n",
    "y_test = y[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first we can start by visualizing our data a little bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(zh, log=True)\n",
    "plt.xlabel('Zh')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(zdr)\n",
    "plt.xlabel('Zdr')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(kdp, log=True)\n",
    "plt.xlabel('Kdp')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(d0)\n",
    "plt.xlabel('$D_0$')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(nw)\n",
    "plt.xlabel('$N_W$')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(mu)\n",
    "plt.xlabel('$\\mu$')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's take a look at some of the relations between these variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist2d(d0, zdr, bins=100);\n",
    "plt.xlabel('D0')\n",
    "plt.ylabel('Zdr')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist2d(d0, zh, bins=100);\n",
    "plt.xlabel('D0')\n",
    "plt.ylabel('Zh')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist2d(d0, kdp, bins=100);\n",
    "plt.xlabel('D0')\n",
    "plt.ylabel('Kdp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises:\n",
    "1. What appears to be the per variable variability for different regions? \n",
    "2. What is wrong with the 3rd plot? How can we fix this? \n",
    "3. Plot some of the other relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now that we understand our data a little bit better, we would start by trying to fit some simple relationships. In general we tend to use power law type fits for most of these. For instance:\n",
    "\n",
    "$$ D_0 = \\alpha Z_{DR}^b $$\n",
    "\n",
    "These ...work. More so for some variables than others. We can see in our images though that even for D0, this fails to account for the Mie variability in the scattering. Can we do better by using machine learning and a more advanced estimator? It turns out..remarkably yes. \n",
    "\n",
    "We will start by training an ensemble classifier called Random Forest. This trains a series of estimation trees, then merges the output. As this is part of scikit learn, we can just pass in our normal style of data (x_train, y_train). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor( random_state=0, n_estimators=2, max_depth=3)\n",
    "regr.fit(X_train, y_train)\n",
    "print(regr.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.predict(X_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(y_predict[:,0], y_test[:,0])\n",
    "plt.xlabel('Actual D0')\n",
    "plt.ylabel('Predicted D0')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(y_predict[:,1], y_test[:,1])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(y_predict[:,2], y_test[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is...not good. Well above we forced these trees to be very shallow, and not many of them. We can try increasing the size of our tree to get a little bit more learning power. \n",
    "\n",
    "Try increasing the size of the tree some. \n",
    "\n",
    "### Exercises:\n",
    "1. Try changing the size of the tree and rerunning the next two cells below. What works best for you?\n",
    "2. Why do we avoid making our tree too big? \n",
    "3. What other parameters might we want to change. the documentation is at: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 2\n",
    "max_depth=3\n",
    "regr = RandomForestRegressor( random_state=0, n_estimators=n_estimators, max_depth=max_depth)\n",
    "regr.fit(X_train, y_train)\n",
    "print(regr.feature_importances_)\n",
    "\n",
    "y_predict = regr.predict(X_test)\n",
    "print(regr.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(y_predict[:,0], y_test[:,0])\n",
    "plt.xlabel('Actual D0')\n",
    "plt.ylabel('Predicted D0')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(y_predict[:,1], y_test[:,1])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(y_predict[:,2], y_test[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay that is __MUCH__ better. Let's introduce a loss metric to figure out just how good it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(yHat, y):\n",
    "    return np.sum((yHat - y)**2) / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D0_loss = MSE(y_predict[:,0], y_test[:,0])\n",
    "Nw_loss = MSE(y_predict[:,1], y_test[:,1])\n",
    "mu_loss = MSE(y_predict[:,2], y_test[:,2])\n",
    "print(D0_loss, Nw_loss, mu_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see the random forest was able to very accurately capture D0 and Nw, but did a mediocre job on $\\mu$. This is not completely unsurprising as $\\mu$ is a very hard variable to capture. This performance is __very__ good. \n",
    "\n",
    "## Exploration\n",
    "So now lets try a few things to see if we can do any better. \n",
    "1. Can we visualize why $\\mu$ is worse? \n",
    "2. Does this imply anything about $\\mu$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Trees Regression\n",
    "Let's try another algorithm and see if we can do better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "est_D0 = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,  random_state=0, loss='ls')\\\n",
    "    .fit(X_train, y_train[:,0])# clf.score(X_test, y_test)\n",
    "est_Nw = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=0, loss='ls')\\\n",
    "    .fit(X_train, y_train[:,1])# clf.score(X_test, y_test)\n",
    "est_mu = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='ls')\\\n",
    "    .fit(X_train, y_train[:,2])# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE(y_test[:,0], est_D0.predict(X_test)))\n",
    "print(MSE(y_test[:,1], est_Nw.predict(X_test)))\n",
    "print(MSE(y_test[:,2], est_mu.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise if time:\n",
    "1. What can we change here? \n",
    "2. What was different about this training? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
